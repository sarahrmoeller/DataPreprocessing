{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code by Zachary J. Ryan \n",
    "at CU Boulder\n",
    "Spring 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API for parsing XML docs\n",
    "import xml.etree.ElementTree as ET\n",
    "from itertools import chain\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def XMLtoArray(filename, stems=False):\n",
    "    '''Takes multiple FLExText texts as .xml'''\n",
    "    \n",
    "    # Identify tiers, because the info you need may be on different tiers in FLEx.\n",
    "    txt = 'txt'\n",
    "    gloss = 'gls'\n",
    "    cf = 'cf'\n",
    "    pos = 'pos' # word-level pos\n",
    "    msa = 'msa' # morpheme-level pos\n",
    "    punct = 'punct'\n",
    "    variantTypes = 'variantTypes'\n",
    "    title_type = 'title'\n",
    "    comment_type = 'comment'\n",
    "    english = 'en'\n",
    "    indonesian = 'id'\n",
    "    stems = ['stem', 'bound stem', 'bound root A', 'root', 'particle']\n",
    "    prefix = 'prefix'\n",
    "    suffix = 'suffix'\n",
    "    enclitic = 'enclitic'\n",
    "    phrase_type = 'phrase'\n",
    "    circumfix = 'circumfix'\n",
    "    infix = 'infix'\n",
    "    \n",
    "    datalists = []\n",
    "    #a single line for datalists is below\n",
    "    #datalists -> [title, segnum, [[word_1,[[morph, gloss]], pos], [wordn,[[morph, gloss], [morph, gloss]], pos]], translated phrase, comment]\n",
    "    \n",
    "    # open XML doc using xml parser\n",
    "    root = ET.parse(filename).getroot()\n",
    "    for lin in root.iter('interlinear-text'):\n",
    "        #find title and comment if in this section\n",
    "        #some documents have both and english and native language titles\n",
    "        #these checks assure that the both will always be used if both are found\n",
    "        #if only one of them is found then it is used\n",
    "        #if none are found return NO TITLE FOUND\n",
    "        comment = \"No comment\"\n",
    "        eng_title = \"~~~\"\n",
    "        non_eng_title = \"~~~\"\n",
    "        for item_lin in lin.iter('item'):\n",
    "            if item_lin.get('type') == title_type and item_lin.get('lang') == english:\n",
    "                eng_title = item_lin.text\n",
    "            if item_lin.get('type') == title_type and item_lin.get('lang') != english:\n",
    "                non_eng_title = item_lin.text\n",
    "            if item_lin.get('type') == comment_type and item_lin.get('lang') == english:\n",
    "                comment = item_lin.text\n",
    "        if eng_title != \"~~~\" and non_eng_title == \"~~~\":\n",
    "            title = eng_title \n",
    "        elif eng_title == \"~~~\" and non_eng_title != \"~~~\":\n",
    "            title = non_eng_title\n",
    "        elif eng_title != \"~~~\" and non_eng_title != \"~~~\":\n",
    "            title = eng_title + ' ' + non_eng_title \n",
    "        else:\n",
    "            title = \"NO TITLE FOUND\"\n",
    "            \n",
    "        #go through all paragraphs\n",
    "        for paragraphs in lin.iter('paragraphs'):\n",
    "            for paragraph in paragraphs.iter('paragraph'):\n",
    "                #go through all phrases in paragraph\n",
    "                for phrases in paragraph.iter('phrases'):\n",
    "                    for phrase in phrases.iter('phrase'):\n",
    "                        #create a temp array for each phrase\n",
    "                        temp_line = []\n",
    "                        #append title\n",
    "                        temp_line.append(title)\n",
    "                        #get segnum to temp_line\n",
    "                        segnum = phrase.find('item').text\n",
    "                        temp_line.append(segnum)\n",
    "                        temp_words_morph_gloss = []\n",
    "                        #loop through all words in the phrase\n",
    "                        for words in phrase.iter('words'):\n",
    "                            for word in words.iter('word'):\n",
    "                                temp_word = []\n",
    "                                #attach the untranslated word\n",
    "                                wrd = word.find('item')\n",
    "                                if wrd.get('type') == punct:\n",
    "                                    temp_word.append(wrd.text)\n",
    "                                    # make sure all new entries go within both sets of brackets, \n",
    "                                    #follow the same format right after 'punct'\n",
    "                                    temp_morph = [[str(wrd.text), str(wrd.text), 'punct', '', '']]\n",
    "                                    temp_word.append(temp_morph)\n",
    "                                    temp_word.append('punct')\n",
    "                                    \n",
    "                                else:\n",
    "                                    # multi-word lexical items joined by ~\n",
    "                                    temp_word.append(wrd.text.replace(' ', '~'))\n",
    "                                    #find the morph, morpheme, and gloss for each word and append\n",
    "                                    temp_morphemes = []\n",
    "                                    #stores the order of the morphemes for each word, resets each iteration of the loop\n",
    "                                    #used in circumfix to decide what formatting is needed\n",
    "                                    affix_order = []\n",
    "                                    for morph in word.iter('morph'):\n",
    "                                        #if you want to add more items that are found in each morpheme add the code here\n",
    "                                        #note this needs to be done for each morph type\n",
    "                                        #first add another holding place in the the temp_morph array\n",
    "                                        #then add an elif statement that is of the same type already seen but instead \n",
    "                                        #check for whatever tag you want, here 'gloss' is one.\n",
    "                                        #also if you do add more entries into the temp_morph you should keep it uniform\n",
    "                                        #for the punctuation option above and entries to the temp morph as well.\n",
    "                                        if(morph.get('type') in stems) or (morph.get('type') == None):\n",
    "                                            affix_order.append(morph.get('type'))\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\",\"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','').replace(' ', '.')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    temp_morph[0] = item.text.replace('-...-','<>')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # join multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        temp_morph[1] = gloss_line\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == prefix):\n",
    "                                            affix_order.append(prefix)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    if '-...-' in item.text:\n",
    "                                                        #print(wrd.text)\n",
    "                                                        #print(item.text)\n",
    "                                                        temp_morph[0] = item.text.replace('-...-','<>') + '>-'\n",
    "                                                        #print('prefix: '+temp_morph[0])\n",
    "                                                    else:\n",
    "                                                        temp_morph[0] = item.text.replace('-...-','<>')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        # make all affixes upper case as per linguistic convention\n",
    "                                                        temp_morph[1] = gloss_line.upper()\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == suffix):\n",
    "                                            affix_order.append(suffix)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    if '-...-' in item.text:\n",
    "                                                        #print(wrd.text)\n",
    "                                                        #print(item.text)\n",
    "                                                        temp_morph[0] = '-<' + item.text.replace('-...-','<>')\n",
    "                                                        #print('suffix: '+temp_morph[0])\n",
    "                                                    else:\n",
    "                                                        temp_morph[0] = item.text.replace('-...-','<>')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        # make all affixes upper case as per linguistic convention\n",
    "                                                        temp_morph[1] = gloss_line.upper()\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == enclitic):\n",
    "                                            affix_order.append(enclitic)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = '-'+item.text.replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    temp_morph[0] = '-'+item.text.replace('-...-','<>')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        # make all affixes upper case as per linguistic convention\n",
    "                                                        temp_morph[1] = '-'+gloss_line.upper()\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == phrase_type):\n",
    "                                            affix_order.append(phrase_type)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','').replace(' ', '.')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    temp_morph[0] = item.text.replace('-...-','<>').replace(' ', '.')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        # make all affixes upper case as per linguistic convention\n",
    "                                                        temp_morph[1] = gloss_line\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == circumfix):\n",
    "                                            affix_order.append(circumfix)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    #print('txt: ' + item.text)\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    #if cicrumfix is the first morpheme in the word, treat similar to a prefix\n",
    "                                                    #if not the first morpheme then treat it as a suffix\n",
    "                                                    if affix_order[0] == circumfix:\n",
    "                                                        #print('cf: ' + item.text)\n",
    "                                                        #print(affix_order)\n",
    "                                                        temp_morph[0] = item.text.replace('-...-','<>')+'>-'\n",
    "                                                        #print(temp_morph[0])\n",
    "                                                    else:\n",
    "                                                        #print('cf: ' + item.text)\n",
    "                                                        #print(affix_order)\n",
    "                                                        temp_morph[0] = '-<'+item.text.replace('-...-','<>')\n",
    "                                                        #print(temp_morph[0])\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        # make all affixes upper case as per linguistic convention\n",
    "                                                        temp_morph[1] = gloss_line.upper()\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        elif(morph.get('type') == infix):\n",
    "                                            affix_order.append(infix)\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    #eliminates the dashes on the outside of the text\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_txt1 = item.text[1:-1]\n",
    "                                                        temp_morph[3] = wrd.text.replace(temp_txt1, ' '+item.text+' ').replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    #eliminates the dashes on the outside of the text\n",
    "                                                    temp_txt1 = item.text[1:-1]\n",
    "                                                    temp_morph[0] = wrd.text.replace(temp_txt1, ' '+item.text+' ').replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        temp_morph[1] = gloss_line\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                            temp_morphemes.append(temp_morph)\n",
    "                                        #end of morpheme checks, else statement will catch any other type and put into the general format\n",
    "                                        else:\n",
    "                                            print(\"morpheme type not checked for: \" + str(morph.get('type')))\n",
    "                                            temp_morph = [\"~~~\", \"~~~\", \"~~~\", \"~~~\", \"~~~\"]\n",
    "                                            for item in morph.iter('item'):\n",
    "                                                if(item.get('type') == txt):\n",
    "                                                    if item.text != None:\n",
    "                                                        temp_morph[3] = item.text.replace('-...-','<>').replace('Ø','')\n",
    "                                                elif(item.get('type') == cf):\n",
    "                                                    temp_morph[0] = item.text.replace('-...-','<>')\n",
    "                                                elif(item.get('type') == gloss):\n",
    "                                                    # separate multi-word glosses with \".\"\n",
    "                                                    gloss_line = item.text\n",
    "                                                    if gloss_line != None:\n",
    "                                                        gloss_line = gloss_line.strip().replace(' ','.').replace('-','.')\n",
    "                                                        temp_morph[1] = gloss_line\n",
    "                                                elif(item.get('type') == msa):\n",
    "                                                    temp_morph[2] = item.text.replace(' ', '').replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                                elif(item.get('type') == variantTypes):\n",
    "                                                    temp_morph[4] = item.text\n",
    "                                                else:\n",
    "                                                    continue\n",
    "                                    temp_word.append(temp_morphemes)\n",
    "                                    #look for pos for the individual word\n",
    "                                    temp_pos = '~~~'\n",
    "                                    for w_item in word.iter('item'):\n",
    "                                        if(w_item.get('type') == pos):\n",
    "                                            temp_pos = w_item.text.replace('pro-form', 'proform').replace('Nom-1','Nom1').replace('N (kx cl)', 'N.(kx.cl)')\n",
    "                                        else:\n",
    "                                            continue\n",
    "                                    temp_word.append(temp_pos)\n",
    "                                temp_words_morph_gloss.append(temp_word)\n",
    "                            #finding the phrase translation, starts with a string of '~~~'\n",
    "                            en_translation = '~~~'\n",
    "                            id_translation = '~~~'\n",
    "                            #iterate through all 'item' in branch phrase\n",
    "                            temp_phrase_gloss = [p_item for p_item in phrase.iter('item')]\n",
    "                            #take the last item which should be our phrase translation but the if statement checks to make sure\n",
    "                            for tmg in temp_phrase_gloss:\n",
    "                                if tmg.get('type') == gloss and tmg.get('lang') == english:\n",
    "                                    en_translation = tmg.text\n",
    "                                if tmg.get('type') == gloss and tmg.get('lang') == indonesian:\n",
    "                                    id_translation = tmg.text\n",
    "                            #append all the words with there morpheme and gloss array\n",
    "                            temp_line.append(temp_words_morph_gloss)\n",
    "                            #append the translation of the phrase to the end of the temp line\n",
    "                            temp_line.append(en_translation)\n",
    "                            temp_line.append(id_translation)\n",
    "                            #append whatever comment may have been found\n",
    "                            temp_line.append(comment)\n",
    "                            #append each phrase to datalist\n",
    "                            #print(temp_line)\n",
    "                            datalists.append(temp_line)\n",
    "    \n",
    "    return datalists\n",
    "\n",
    "\n",
    "def arrayToCSV(xml, langID, fileName):\n",
    "    \n",
    "    with open(fileName, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for i in range(0,len(xml)):\n",
    "            #starts with segnum and lang ID\n",
    "            csv_line = [xml[i][1],langID]\n",
    "            temp_line_phrase = \"\"\n",
    "            temp_line_cf = \"\"\n",
    "            temp_line_txt = \"\"\n",
    "            temp_line_gloss = \"\"\n",
    "            temp_line_msa = \"\"\n",
    "            temp_line_word_pos = \"\"\n",
    "            temp_line_variantTypes = \"\"\n",
    "            for wmg in range(0,len(xml[i][2])):\n",
    "                temp_line_phrase += (str(xml[i][2][wmg][0])+\" \")\n",
    "                temp_cf = \"\"\n",
    "                temp_gloss = \"\"\n",
    "                temp_msa = \"\"\n",
    "                temp_txt = \"\"\n",
    "                temp_variantTypes = \"\"\n",
    "                temp_line_word_pos += (str(xml[i][2][wmg][2])+\" \")\n",
    "                for mg in range(0, len(xml[i][2][wmg][1])):\n",
    "                    if mg == (len(xml[i][2][wmg][1])-1):\n",
    "                        temp_cf += (str(xml[i][2][wmg][1][mg][0]))\n",
    "                        temp_gloss += (str(xml[i][2][wmg][1][mg][1]))\n",
    "                        temp_msa   += (str(xml[i][2][wmg][1][mg][2]))\n",
    "                        temp_txt   += (str(xml[i][2][wmg][1][mg][3]))\n",
    "                        temp_variantTypes += (str(xml[i][2][wmg][1][mg][4]))\n",
    "                    else:\n",
    "                        temp_cf += (str(xml[i][2][wmg][1][mg][0])+\" \")\n",
    "                        temp_gloss += (str(xml[i][2][wmg][1][mg][1])+\" \")\n",
    "                        temp_msa   += (str(xml[i][2][wmg][1][mg][2])+\" \")\n",
    "                        temp_txt   += (str(xml[i][2][wmg][1][mg][3])+\" \")\n",
    "                        temp_variantTypes += (str(xml[i][2][wmg][1][mg][4])+\" \")\n",
    "                temp_line_cf += (temp_cf+\"\\t\")\n",
    "                temp_line_gloss += (temp_gloss+\"\\t\")\n",
    "                temp_line_msa += (temp_msa+\"\\t\")\n",
    "                temp_line_txt += (temp_txt+\"\\t\")\n",
    "                temp_line_variantTypes += (temp_variantTypes+\"\\t\")\n",
    "                \n",
    "                \n",
    "            csv_line.append(temp_line_phrase)\n",
    "            csv_line.append(temp_line_txt)\n",
    "            csv_line.append(temp_line_cf)\n",
    "            csv_line.append(temp_line_gloss)\n",
    "            csv_line.append(xml[i][3]) #appends the english translation\n",
    "            csv_line.append(xml[i][4]) #appends the indonesian translation\n",
    "            csv_line.append(\"ML ID\")\n",
    "            csv_line.append(xml[i][5]) #append the comment found from file\n",
    "            csv_line.append(xml[i][0]) #appends the title or Text_ID\n",
    "            csv_line.append(temp_line_msa) #appends the morphemes POS\n",
    "            csv_line.append(temp_line_word_pos) #appends the POS for each word\n",
    "            csv_line.append(temp_line_variantTypes)\n",
    "            \n",
    "            writer.writerow(csv_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = r'./'\n",
    "OUT_DIR = r'./CLDF/'\n",
    "flexlgs = ['btz', 'lez', 'lmk', 'mni', 'ntu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 - Si Layakh', '1.1', [['Alkisah', [['alkisah', 'The.story.is.told', 'n', 'alkisah', '~~~']], 'n'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['ni', [['ni', 'in,.at.(space)', 'Prep', 'ni', '~~~']], 'Prep'], ['sebuah', [['sebuah', 'one', 'distrnum', 'sebuah', '~~~']], 'distrnum'], ['kute', [['kute', 'city', 'n', 'kute', '~~~']], 'n'], ['(', [['(', '(', 'punct', '', '']], 'punct'], ['kute', [['kute', 'city', 'n', 'kute', '~~~']], 'n'], ['neggekhi', [['neggekhi', 'Nagari', 'nprop', 'neggekhi', '~~~']], 'nprop'], ['desa', [['desa', 'village', 'n', 'desa', '~~~']], 'n'], [')', [[')', ')', 'punct', '', '']], 'punct'], ['megelakh', [['me-', 'TO.HAVE....', 'n>vi', 'me-', '~~~'], ['gelakh', 'title.(of.persons)', 'n', 'gelakh', '~~~']], 'vi'], ['kute', [['kute', 'city', 'n', 'kute', '~~~']], 'n'], ['kekhan', [['kekhan', 'Engkeran', 'nprop', 'kekhan', '~~~']], 'nprop'], ['si', [['si', 'relpro', 'relpro', 'si', '~~~']], 'relpro'], ['megelakh~ken', [['N<>ken>-', '~~~', 'n>vt', 'me-', '+unspec. var. of'], ['gelakh', 'title.(of.persons)', 'n', 'gelakh', '~~~'], ['-<N<>ken', '~~~', 'n>vt', '-ken', '~~~']], 'vt'], ['salah~sebuah', [['salah.sebuah', 'One.of', 'adj', 'salah.sebuah', '~~~']], 'adj'], ['tanoh', [['tanoh', 'land', 'n', 'tanoh', '~~~']], 'n'], ['alas', [['alas', 'alas', 'nprop', 'alas', '~~~']], 'nprop'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['kabupaten', [['kabupaten', 'county', 'n', 'kabupaten', '~~~']], 'n'], ['aceh', [['aceh', 'Aceh', 'nprop', 'aceh', '~~~']], 'nprop'], ['tenggakhe', [['tenggakhe', 'southeast', 'adj', 'tenggakhe', '~~~']], 'adj'], ['sendah~ende', [['sendhah', 'moment', 'n', 'sendah', '+dial. var. of'], ['endhe', 'this', 'dem', 'ende', '+sp. var. of']], 'n'], ['.', [['.', '.', 'punct', '', '']], 'punct']], 'Once upon a time in a town (Red-Gampong, Nagari, village) called Engkeran Town which is one of the regions of Alas Land, which is the district of Southeast Aceh today.', 'Alkisah di suatu kuta (Red-Gampong, Nagari, desa), bernama kuta Engkeran yang merupakan salah satu wilayah Tanah Alas, Kabupaten Aceh Tenggara saat ini.', 'This appears to be a translation of part of the story from https://kaisosogarcia.blogspot.com/2016/04/si-layakh-cerita-rakyat-dari-kutacane.html. However, I have been told the Alas is good in it.']\n",
      "['He had a dog 02 Адаз кицӀ авай тир', '1.1', [['Са', [['са', 'one', 'cardnum', 'са', '~~~']], 'cardnum'], ['юкъуз', [['юкъ', '~~~', 'n', 'юкъ', '~~~'], ['-ди', 'OBL', 'n:(OBLIQUEstem)', '-у', '~~~'], ['-з', 'DAT', 'n:(CASE)', '-з', '~~~']], 'n'], ['зун', [['зун', '1sg.abs', 'pers', 'зун', '~~~']], 'pers'], ['хуьряй', [['хуьр', 'village', 'n', 'хуьр', '~~~'], ['-ай', 'INELAT', 'n:(OBLIQUEstem)', '-ай', '~~~']], 'n'], ['КцӀариз', [['кцӏар', 'gusar', 'n', 'кцӏар', '~~~'], ['-ди', 'OBL', 'n:(OBLIQUEstem)', '-и', '~~~'], ['-з', 'DAT', 'n:(CASE)', '-з', '~~~']], 'n'], ['хквезвай', [['хквен', 'return', 'v', 'хкве', '~~~'], ['-зва', 'IMPF', 'v:TAM1', '-зва', '~~~'], ['-й', 'PST', 'cop:(TAM)', '-й', '~~~']], 'Vnf'], ['тир', [['тир', 'was', 'v', 'тир', '~~~']], 'v'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['рекъе', [['рекъ', 'way,.road', 'n', 'рекъ', '~~~'], ['-е', 'INESS', 'n:(OBLIQUEstem)', '-е', '~~~']], 'n'], ['са', [['са', 'one', 'cardnum', 'са', '~~~']], 'cardnum'], ['стӀурви', [['стӀурви', 'from.Sudur', 'n', 'стӀурви', '~~~']], 'n'], ['стхадал', [['стха', 'brother', 'n', 'стха', '~~~'], ['-е', 'INESS', 'n:(OBLIQUEstem)', '-да', '~~~'], ['-л', 'SPSS', 'n:(CASE)', '-л', '~~~']], 'n'], ['гьалтна', [['гьалтун', 'meet', 'v', 'гьалт', '~~~'], ['-на', 'AOR', 'v:TAM1', '-на', '~~~']], 'Vf'], ['.', [['.', '.', 'punct', '', '']], 'punct']], 'One day I was on my way from the village to Gusar. \\u200e\\u200eI met one man from Sudur. ', '~~~', 'true-ish second-hand story']\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: bound root\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: bound root\n",
      "morpheme type not checked for: bound root\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: infixing interfix\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: bound root\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "morpheme type not checked for: clitic\n",
      "['Escape of the Younger Brother (Grierson) [Thei sikvoor Bul NR0001 ?]', '1', [['Alraang~ngi', [['alraang', 'long.ago', 'advl', 'alraang', '~~~'], ['-=ngi', '-=SOURCE', 'ptc', '-=ngi', '~~~']], 'advl'], ['khuu', [['khuù', 'village', 'n', 'khuu', '~~~']], 'n'], ['khat', [['~~~', 'one', 'num', 'khát', '~~~']], 'num'], ['thung~ngi', [['thuḥ', 'inside', 'postn', 'thung', '~~~'], ['-=ngi', '-=SOURCE', 'ptc', '-=ngi', '~~~']], 'postp'], [\"m'uu\", [['m-', '3.POS', 'n:Any', 'm-', '~~~'], ['ūū', 'elder', 'n', \"'uu\", '~~~']], 'n'], [\"le'\", [[\"le'\", 'and', 'conn', \"le'\", '~~~']], 'conn'], ['mnao', [['m-', '3.POS', 'n:Any', 'm-', '~~~'], ['naò', 'child', 'n', 'nao', '~~~']], 'n'], ['khat', [['~~~', 'one', 'num', 'khát', '~~~']], 'num'], ['am~lam~da', [['ām', 'be', 'vi', 'am', '~~~'], ['-lam', '3.PL', 'v:Any', '-lam', '~~~'], ['-da', 'SBJ:3.PFV', '~~~', '-da', '~~~']], 'v'], ['.', [['.', '.', 'punct', '', '']], 'punct']], 'In an ancient times in a village of long ago an elder brother and his younger brother lived.', '~~~', '[same story as 356] conceptually, perhaps.']\n",
      "['The Right Attitude, the Right Form Čə́pčábə Phirép, Čə́pčábə Wárép', '1', [['khúdə́m', [['khút', 'hand', 'n', 'khúd', '~~~'], ['lə́m', 'path', 'n', 'də́m', '~~~']], 'n'], ['oynə', [['oy', 'be', '<NotSure>', 'oy', '~~~'], ['-nə', '.ADV', 'Attachestoanycategory', '-nə', '~~~']], '~~~'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['yam', [['yam', 'much', '<NotSure>', 'yam', '~~~']], '~~~'], ['waŋnə', [['waŋ', 'high', '<NotSure>', 'waŋ', '~~~'], ['-nə', '.ADV', 'Attachestoanycategory', '-nə', '~~~']], '~~~'], ['haygətnə', [['hay', 'sway', 'v', 'hay', '~~~'], ['-khət', '.UP', 'v>v', '-gət', '~~~'], ['-nə', '.ADV', 'Attachestoanycategory', '-nə', '~~~']], 'v'], ['kəyno', [['kəri', 'what', '<NotSure>', 'kəy', '~~~'], ['=no', '=INQ', '<NotSure>', '-no', '~~~']], 'adv'], ['təwbidrə́gəsú', [['təw', 'do', '<NotSure>', 'təw', '~~~'], ['-pi', '.REC', 'Attachestoanycategory', '-bi', '~~~'], ['-tə', '.NEG', '<NotSure>', '-d', '~~~'], ['-lə́gə', '.AFTER', 'Attachestoanycategory', '-rə́gə', '~~~'], ['-čhú', '.ALSO', 'Attachestoanycategory', '-sú', '~~~']], '~~~'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['tə́rahumdə', [['tə́ra', 'ten', '<NotSure>', 'tə́ra', '~~~'], ['hum', 'three', '<NotSure>', 'hum', '~~~'], ['-=tə', '-==LOC', '<NotSure>', '-=də', '~~~']], '~~~'], ['oybəsú', [['oy', 'be', '<NotSure>', 'oy', '~~~'], ['-pə', '.NOM', 'v>n', '-bə', '~~~'], ['-čhú', '.ALSO', 'Attachestoanycategory', '-sú', '~~~']], '~~~'], ['parti', [['parti', 'party', 'n', 'parti', '~~~']], 'n'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['koŋgrés', [['koŋgrés', 'Congress', 'n', 'koŋgrés', '~~~']], 'n'], ['ŋə́sidəgi', [['ŋə́čhi', 'today', '<NotSure>', 'ŋə́si', '~~~'], ['-=təgi', '-==ABL', '<NotSure>', '-=dəgi', '~~~']], '~~~'], ['čə́hí', [['čə́hí', 'year', 'n', 'čə́hí', '~~~']], 'n'], ['mə́ŋaromgi', [['mə́ŋa', 'five', '<NotSure>', 'mə́ŋa', '~~~'], ['-lom', '.APX', 'Attachestoanycategory', '-rom', '~~~'], ['-=ki', '-==POSS', '<NotSure>', '-=gi', '~~~']], '~~~'], ['mə́maŋdə', [['mə́-', 'NM.', 'Attachestoanycategory', 'mə́-', '~~~'], ['maŋ', 'front', '<NotSure>', 'maŋ', '~~~'], ['-=tə', '-==LOC', '<NotSure>', '-=tə', '~~~']], '~~~'], ['phə́mkhibə', [['phə́m', 'sit', 'v', 'phə́m', '~~~'], ['-khi', '.STILL', 'Attachestoanycategory', '-khi', '~~~'], ['-pə', '.NOM', 'v>n', '-bə', '~~~']], '~~~'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['mə́dúgi', [['mə́-', 'NM.', 'Attachestoanycategory', 'mə́-', '~~~'], ['tú', 'ddet', '<NotSure>', 'dú', '~~~'], ['-=ki', '-==POSS', '<NotSure>', '-=gi', '~~~']], '~~~'], ['mə́thə́k', [['mə́-', 'NM.', 'Attachestoanycategory', 'mə́-', '~~~'], ['thə́k', 'up', '<NotSure>', 'thə́k', '~~~']], '~~~'], ['čə́hí', [['čə́hí', 'year', 'n', 'čə́hí', '~~~']], 'n'], ['tə́ramúkki', [['tə́ra', 'ten', '<NotSure>', 'tə́ra', '~~~'], ['múk', 'once', '<NotSure>', 'múk', '~~~'], ['-=ki', '-==POSS', '<NotSure>', '-=ki', '~~~']], '~~~'], ['mə́maŋdə', [['mə́-', 'NM.', 'Attachestoanycategory', 'mə́-', '~~~'], ['maŋ', 'front', '<NotSure>', 'maŋ', '~~~'], ['-=tə', '-==LOC', '<NotSure>', '-=tə', '~~~']], '~~~'], ['phə́mkhibə', [['phə́m', 'sit', 'v', 'phə́m', '~~~'], ['-khi', '.STILL', 'Attachestoanycategory', '-khi', '~~~'], ['-pə', '.NOM', 'v>n', '-bə', '~~~']], '~~~'], [',', [[',', ',', 'punct', '', '']], 'punct'], ['kəya', [['kəya', 'how.many', '<NotSure>', 'kəya', '~~~']], '~~~'], ['ə́mə', [['ə́-', 'ATT.', 'Attachestoanycategory', 'ə́-', '~~~'], ['mə', 'one', '<NotSure>', 'mə', '~~~']], '~~~'], ['píbə', [['pí', 'give', 'v', 'pí', '~~~'], ['-pə', '.NOM', 'v>n', '-pə', '~~~']], '~~~'], ['yay', [['ya', 'possible', '<NotSure>', 'ya', '~~~'], ['-í', '.NHYP', 'Verb', '-y', '~~~']], 'n'], ['.', [['.', '.', 'punct', '', '']], 'punct']], \"...for example, even if you don't turn back the pages further than fifteen to twenty years ago, you can think of appropriate examples. That thirteenth Congress that was in power five years ago, and also the ones that were in power ten years previous to those five years, these can be given as examples.\", '~~~', 'No comment']\n",
      "['SGM 28 SGM 28', '1', [['28', [['~~~', '~~~', '~~~', '28', '~~~']], '~~~'], ['.', [['.', '.', 'punct', '', '']], 'punct'], ['Vex', [['ve', 'accompany', 'V', 've', '~~~'], ['-=x', '-=1MINᵢ', 'Nom1', '-=x', '~~~']], '~~~'], ['Dckta~Foks', [['~~~', '~~~', '~~~', 'Dckta.Foks', '~~~']], '~~~'], ['Mz', [['mz', 'PREP', 'PREP', 'mz', '~~~']], 'PREP'], ['Nzamukxtr-krde', [['nz-', 'NMLZ', 'V>N', 'nz-', '~~~'], ['a-', 'CAUS', 'V:Any', 'a-', '~~~'], ['mu', 'eat', 'V', 'mu', '~~~'], ['kx', 'SUBR', 'SUBR', 'kx', '~~~'], ['tr', 'holy', 'V', 'tr', '~~~'], ['-kr', 'NMLZ.POSS', 'V>N', '-kr', '~~~'], ['-=de', '-=3MINᵢᵢ', 'A-D-P2', '-=de', '~~~']], '~~~'], ['Pawa', [['Pawa', 'Pawa.school', 'N', 'Pawa', '~~~']], '~~~'], ['Skul', [['skul', 'be.schooled', 'V', 'skul', '~~~']], 'V']], '28. I accompany Doctor Fox When he Celebrates Holy Communion at Pawa School ', '~~~', 'No comment']\n"
     ]
    }
   ],
   "source": [
    "for lg in flexlgs:\n",
    "    source_file = lg + '-all_txts.flextext'\n",
    "    datalists = XMLtoArray(source_file, stems=True)\n",
    "    print(datalists[0])\n",
    "    outputfile = OUT_DIR + lg + '-CLDFMaster.csv'\n",
    "    arrayToCSV(datalists, lg, outputfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master2Gold(isocode):\n",
    "    '''If missing element in Morphemes, Analyzed Word,\n",
    "    Gloss, or Translation.'''\n",
    "    \n",
    "    masterfile = OUT_DIR + isocode + '-CLDFmaster.csv'\n",
    "    goldfile = OUT_DIR + isocode + '-CLDFgold.csv'\n",
    "    otherfile = OUT_DIR + isocode + '-CLDFincomplete.csv'\n",
    "    \n",
    "    with open(masterfile) as master, open(goldfile, 'w') as gold, open(otherfile, 'w') as other:\n",
    "        mreader = csv.reader(master)\n",
    "        masterlines = list(mreader)\n",
    "        goldwriter = csv.writer(gold, delimiter=',')\n",
    "        otherwriter = csv.writer(other, delimiter=',')\n",
    "        \n",
    "        # Get header row\n",
    "        otherwriter.writerow(masterlines[0])\n",
    "        goldwriter.writerow(masterlines[0])\n",
    "        \n",
    "        # write to gold or non-gold files\n",
    "        for line in masterlines[1:]:\n",
    "            if '~~~' in line[3] or '~~~' in line[4] or '~~~' in line[5] or '~~~' in line[6]:\n",
    "                otherwriter.writerow(line)\n",
    "            else:\n",
    "                goldwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lg in flexlgs:\n",
    "    master2Gold(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
